{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test social variable collinearity\n",
    "Some of the social variables may be related e.g. language use and media sharing. Let's assess this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loanword</th>\n",
       "      <th>loanword_verb</th>\n",
       "      <th>loanword_type</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>user_id</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>user_description</th>\n",
       "      <th>user_location</th>\n",
       "      <th>...</th>\n",
       "      <th>us_american_artist_video_count</th>\n",
       "      <th>latin_american_artist_video_pct</th>\n",
       "      <th>total_music_count</th>\n",
       "      <th>latin_american_music_genre_pct</th>\n",
       "      <th>latin_american_music_genre_count</th>\n",
       "      <th>us_american_music_genre_count</th>\n",
       "      <th>latin_american_media_count</th>\n",
       "      <th>us_american_media_count</th>\n",
       "      <th>latin_american_media_pct</th>\n",
       "      <th>integrated_verb_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>audit</td>\n",
       "      <td>auditamos</td>\n",
       "      <td>integrated_loanword</td>\n",
       "      <td>garrachavista</td>\n",
       "      <td>779318307585396736</td>\n",
       "      <td>@Sheiladarsy @anticuarta4 Y dime tu cuales 7.6...</td>\n",
       "      <td></td>\n",
       "      <td>892506833197424640</td>\n",
       "      <td>100% a la izquierda</td>\n",
       "      <td>Venezuela</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ban</td>\n",
       "      <td>baneamos</td>\n",
       "      <td>integrated_loanword</td>\n",
       "      <td>emmanuelkiller5</td>\n",
       "      <td>4273648032</td>\n",
       "      <td>@adameamiro Eres tan hipocrita que antes nos h...</td>\n",
       "      <td></td>\n",
       "      <td>882375684823203841</td>\n",
       "      <td>Felicidad?Que es eso, lo que todos siempre me ...</td>\n",
       "      <td>Chihuahua,  Chihuahua</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ban</td>\n",
       "      <td>baneamos</td>\n",
       "      <td>integrated_loanword</td>\n",
       "      <td>danitolocirio13</td>\n",
       "      <td>482233447</td>\n",
       "      <td>@LVPibai Ibai te hace una normal de reclu? Así...</td>\n",
       "      <td></td>\n",
       "      <td>893999585953185793</td>\n",
       "      <td>#21. Me gusta Love Live. Reborn. Baraggan y Es...</td>\n",
       "      <td>Valladolid, España</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>flip</td>\n",
       "      <td>flipas</td>\n",
       "      <td>integrated_loanword</td>\n",
       "      <td>danitolocirio13</td>\n",
       "      <td>482233447</td>\n",
       "      <td>Me echaba unas rankeds ahora que flipas</td>\n",
       "      <td></td>\n",
       "      <td>949837604362612736</td>\n",
       "      <td>#22. Vago...</td>\n",
       "      <td>Valladolid, España</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ban</td>\n",
       "      <td>banear</td>\n",
       "      <td>integrated_loanword</td>\n",
       "      <td>vcf973</td>\n",
       "      <td>883037197754093569</td>\n",
       "      <td>@MiiKeLMsT MIKEEL! CASI ME BANEAN POR COMPRAR ...</td>\n",
       "      <td></td>\n",
       "      <td>899277329012334593</td>\n",
       "      <td>.</td>\n",
       "      <td>Tenerife</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  loanword loanword_verb        loanword_type      screen_name  \\\n",
       "0    audit     auditamos  integrated_loanword    garrachavista   \n",
       "1      ban      baneamos  integrated_loanword  emmanuelkiller5   \n",
       "2      ban      baneamos  integrated_loanword  danitolocirio13   \n",
       "3     flip        flipas  integrated_loanword  danitolocirio13   \n",
       "4      ban        banear  integrated_loanword           vcf973   \n",
       "\n",
       "              user_id                                               text date  \\\n",
       "0  779318307585396736  @Sheiladarsy @anticuarta4 Y dime tu cuales 7.6...        \n",
       "1          4273648032  @adameamiro Eres tan hipocrita que antes nos h...        \n",
       "2           482233447  @LVPibai Ibai te hace una normal de reclu? Así...        \n",
       "3           482233447            Me echaba unas rankeds ahora que flipas        \n",
       "4  883037197754093569  @MiiKeLMsT MIKEEL! CASI ME BANEAN POR COMPRAR ...        \n",
       "\n",
       "                   id                                   user_description  \\\n",
       "0  892506833197424640                                100% a la izquierda   \n",
       "1  882375684823203841  Felicidad?Que es eso, lo que todos siempre me ...   \n",
       "2  893999585953185793  #21. Me gusta Love Live. Reborn. Baraggan y Es...   \n",
       "3  949837604362612736                                       #22. Vago...   \n",
       "4  899277329012334593                                                  .   \n",
       "\n",
       "           user_location  ...  us_american_artist_video_count  \\\n",
       "0              Venezuela  ...                                   \n",
       "1  Chihuahua,  Chihuahua  ...                                   \n",
       "2     Valladolid, España  ...                                   \n",
       "3     Valladolid, España  ...                                   \n",
       "4               Tenerife  ...                                   \n",
       "\n",
       "  latin_american_artist_video_pct total_music_count  \\\n",
       "0                                                     \n",
       "1                                                     \n",
       "2                                                     \n",
       "3                                                     \n",
       "4                                                     \n",
       "\n",
       "  latin_american_music_genre_pct latin_american_music_genre_count  \\\n",
       "0                                                                   \n",
       "1                                                                   \n",
       "2                                                                   \n",
       "3                                                                   \n",
       "4                                                                   \n",
       "\n",
       "  us_american_music_genre_count latin_american_media_count  \\\n",
       "0                                                            \n",
       "1                                                            \n",
       "2                                                            \n",
       "3                                                            \n",
       "4                                                            \n",
       "\n",
       "  us_american_media_count latin_american_media_pct integrated_verb_pct  \n",
       "0                                                                    1  \n",
       "1                                                                       \n",
       "2                                                                    1  \n",
       "3                                                                    1  \n",
       "4                                                                       \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "author_social_data = pd.read_csv('../../data/mined_tweets/loanword_verbs_post_social_data.tsv', sep='\\t')\n",
    "author_social_data.fillna('', inplace=True)\n",
    "display(author_social_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test variable correlations\n",
    "We'll test the correlation between categorical variables with chi-squared test. We will convert the scalar values to categorical values to make things easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "scalar_vars = ['integrated_verb_pct', 'latin_american_media_pct']\n",
    "bins = 4\n",
    "bin_range = [0., 0.25, 0.75]\n",
    "bin_names = ['', 'low', 'mid', 'high'] # add null category for anything below range (default null val is -1)\n",
    "NULL_VAL = -1\n",
    "for scalar_var in scalar_vars:\n",
    "    bin_scalar_var = f'{scalar_var}_bin'\n",
    "    bin_range_names = dict(zip(range(bins), bin_names))\n",
    "    scalar_var_bins = np.digitize(author_social_data.loc[:, scalar_var].apply(lambda x: NULL_VAL if x=='' else x), bins=bin_range)\n",
    "    scalar_var_cat_bins = list(map(bin_range_names.get, scalar_var_bins))\n",
    "    author_social_data = author_social_data.assign(**{\n",
    "        bin_scalar_var : scalar_var_cat_bins\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3275/87610 data\n"
     ]
    }
   ],
   "source": [
    "# let's test all variables to start\n",
    "valid_data = author_social_data.copy()\n",
    "social_vars = ['es_bin', 'integrated_verb_pct_bin', 'description_location_region', 'latin_american_media_pct_bin']\n",
    "for social_var in social_vars:\n",
    "    valid_data = valid_data[valid_data.loc[:, social_var] != '']\n",
    "print('%d/%d data'%(valid_data.shape[0], author_social_data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vars {es_bin} and {integrated_verb_pct_bin} have difference: test-stat=26.399 (p=2.629E-05)\n",
      "vars {es_bin} and {description_location_region} have difference: test-stat=11.490 (p=7.436E-02)\n",
      "vars {es_bin} and {latin_american_media_pct_bin} have difference: test-stat=63.340 (p=5.755E-13)\n",
      "vars {integrated_verb_pct_bin} and {description_location_region} have difference: test-stat=16.596 (p=1.089E-02)\n",
      "vars {integrated_verb_pct_bin} and {latin_american_media_pct_bin} have difference: test-stat=2.527 (p=6.399E-01)\n",
      "vars {description_location_region} and {latin_american_media_pct_bin} have difference: test-stat=14.843 (p=2.151E-02)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "# compute chi-2 stat for all combos\n",
    "N = len(social_vars)\n",
    "var_combos = [(social_vars[i], social_vars[j]) for i in range(N) for j in range(i+1, N)]\n",
    "for var_1, var_2 in var_combos:\n",
    "    var_combo_counts = valid_data.groupby([var_1, var_2]).size().reset_index()\n",
    "    var_contingency_table = pd.pivot(var_combo_counts, index=var_1, columns=var_2, values=0).fillna(0, inplace=False)\n",
    "    test_stat, p_val, dof, expected_table = chi2_contingency(var_contingency_table)\n",
    "    print('vars {%s} and {%s} have difference: test-stat=%.3f (p=%.3E)'%(var_1, var_2, test_stat, p_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK! Significant correlations include:\n",
    "- Language x integrated verb use\n",
    "- Language x media sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's confirm the scalar vars too with Spearman correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vars {es_log} and {integrated_verb_pct_log} have correl=-0.146 (p=5.619E-17)\n",
      "vars {es_log} and {latin_american_media_pct_log} have correl=0.185 (p=1.219E-26)\n",
      "vars {integrated_verb_pct_log} and {latin_american_media_pct_log} have correl=0.000 (p=9.810E-01)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "# convert to log vals\n",
    "scalar_vars = ['es', 'integrated_verb_pct', 'latin_american_media_pct']\n",
    "smooth_val = 1e-2\n",
    "for scalar_var in scalar_vars:\n",
    "    valid_data = valid_data.assign(**{\n",
    "        f'{scalar_var}_log' : np.log(valid_data.loc[:, scalar_var].astype(float)+smooth_val)\n",
    "    })\n",
    "log_scalar_vars = list(map(lambda x: f'{x}_log', scalar_vars))\n",
    "N = len(scalar_vars)\n",
    "var_combos = [(log_scalar_vars[i], log_scalar_vars[j]) for i in range(N) for j in range(i+1, N)]\n",
    "for var_1, var_2 in var_combos:\n",
    "    correl, p_val = spearmanr(valid_data.loc[:, var_1], valid_data.loc[:, var_2])\n",
    "    print('vars {%s} and {%s} have correl=%.3f (p=%.3E)'%(var_1, var_2, correl, p_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK! Language has strong correlations with other variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations with variable subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does this hold up when we consider just a subset of the variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28775/87610 data\n"
     ]
    }
   ],
   "source": [
    "# let's test all variables to start\n",
    "valid_data = author_social_data.copy()\n",
    "social_vars = ['es_bin', 'integrated_verb_pct_bin', 'description_location_region']\n",
    "for social_var in social_vars:\n",
    "    valid_data = valid_data[valid_data.loc[:, social_var] != '']\n",
    "print('%d/%d data'%(valid_data.shape[0], author_social_data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vars {es_bin} and {integrated_verb_pct_bin} have difference: test-stat=8.447 (p=7.652E-02)\n",
      "vars {es_bin} and {description_location_region} have difference: test-stat=34.696 (p=4.935E-06)\n",
      "vars {integrated_verb_pct_bin} and {description_location_region} have difference: test-stat=7.592 (p=2.696E-01)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "# compute chi-2 stat for all combos\n",
    "N = len(social_vars)\n",
    "var_combos = [(social_vars[i], social_vars[j]) for i in range(N) for j in range(i+1, N)]\n",
    "for var_1, var_2 in var_combos:\n",
    "    var_combo_counts = valid_data.groupby([var_1, var_2]).size().reset_index()\n",
    "    var_contingency_table = pd.pivot(var_combo_counts, index=var_1, columns=var_2, values=0).fillna(0, inplace=False)\n",
    "    test_stat, p_val, dof, expected_table = chi2_contingency(var_contingency_table)\n",
    "    print('vars {%s} and {%s} have difference: test-stat=%.3f (p=%.3E)'%(var_1, var_2, test_stat, p_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with just the \"clean\" variables:\n",
    "- Language x location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This all suggests that we should add interaction terms for language and the other variables, or try a residual regression where we first predict using language and then model the residuals with the other variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3] *",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
